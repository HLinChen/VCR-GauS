{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d7b17-af50-42cd-b531-ef61c49c9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the work directory to the imaginaire root.\n",
    "import os, sys, time\n",
    "import pathlib\n",
    "\n",
    "root_dir = pathlib.Path().absolute().parents[0]\n",
    "os.chdir(root_dir)\n",
    "print(f\"Root Directory Path: {root_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5b9e2f-841c-4815-92e0-0c76ed46da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries.\n",
    "import numpy as np\n",
    "import torch\n",
    "import k3d\n",
    "import json\n",
    "import trimesh\n",
    "import plotly.graph_objs as go\n",
    "from collections import OrderedDict\n",
    "# Import imaginaire modules.\n",
    "from submodules.colmap.scripts.python.read_write_model import read_model\n",
    "# from tools import camera, visualize\n",
    "from tools.camera import quaternion\n",
    "from tools.visualize import k3d_visualize_pose, plotly_visualize_pose\n",
    "from process_data.convert_tnt_to_json import load_transformation, align_gt_with_cam\n",
    "from tools.camera_utils import cubic_camera, grid_camera, around_camera, up_camera, bb_camera\n",
    "from tools.math_utils import inv_normalize_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76033016-2d92-4a5d-9e50-3978553e8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the COLMAP data.\n",
    "# colmap_path = \"datasets/lego_ds2\"\n",
    "scene = 'Barn'\n",
    "colmap_path = f\"/your/path/tnt/{scene}\"\n",
    "# read piont clouds from lidar # point cloud\n",
    "pcd = trimesh.load(os.path.join(colmap_path, '{}.ply'.format(colmap_path.split('/')[-1])))\n",
    "# scene = 'c49a8c6cff'\n",
    "# colmap_path = f\"/your/path/ScanNet++/{scene}/dslr\"\n",
    "# pcd = trimesh.load(os.path.join(colmap_path, '../scans/mesh_aligned_0.05.ply'))\n",
    "view_sample_camera = False\n",
    "cameras, images, points_3D = read_model(path=f\"{colmap_path}/sparse\", ext=\".bin\") # w2c extrinsics\n",
    "# Convert camera poses.\n",
    "images = OrderedDict(sorted(images.items()))\n",
    "qvecs = torch.from_numpy(np.stack([image.qvec for image in images.values()]))\n",
    "tvecs = torch.from_numpy(np.stack([image.tvec for image in images.values()]))\n",
    "# Rs = camera.quaternion.q_to_R(qvecs)\n",
    "Rs = quaternion.q_to_R(qvecs)\n",
    "poses = torch.cat([Rs, tvecs[..., None]], dim=-1)  # [N,3,4]  w2c\n",
    "print(f\"# images: {len(poses)}\")\n",
    "print(\"camera height: {}\".format(poses[:, 1, 3].mean()))\n",
    "\n",
    "# # Get the sparse 3D points and the colors. colmap\n",
    "# xyzs = torch.from_numpy(np.stack([point.xyz for point in points_3D.values()]))\n",
    "# rgbs = np.stack([point.rgb for point in points_3D.values()])\n",
    "# rgbs_int32 = (rgbs[:, 0] * 2**16 + rgbs[:, 1] * 2**8 + rgbs[:, 2]).astype(np.uint32)\n",
    "# print(f\"# points: {len(xyzs)}\")\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(colmap_path, f'{scene}_trans.txt')):\n",
    "    trans = load_transformation(os.path.join(colmap_path, f'{scene}_trans.txt'))\n",
    "    pcd.vertices = align_gt_with_cam(pcd.vertices, trans)\n",
    "    \n",
    "xyzs = pcd.vertices[::500]\n",
    "# xyzs = pcd.vertices\n",
    "rgbs = np.random.randint(0, 255, xyzs.shape)\n",
    "rgbs_int32 = (rgbs[:, 0] * 2**16 + rgbs[:, 1] * 2**8 + rgbs[:, 2]).astype(np.uint32)\n",
    "print(f\"# points: {len(xyzs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47862ee1-286c-4877-a181-4b33b7733719",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_depth = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6cf60ec-fe6a-43ba-9aaf-e3c7afd88208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bounding sphere.\n",
    "json_fname = f\"{colmap_path}/meta.json\"\n",
    "with open(json_fname) as file:\n",
    "    meta = json.load(file)\n",
    "trans = np.array(meta[\"trans\"])\n",
    "scale = np.array(meta[\"scale\"])\n",
    "# ------------------------------------------------------------------------------------\n",
    "# These variables can be adjusted to make the bounding sphere fit the region of interest.\n",
    "# The adjusted values can then be set in the config as data.readjust.center and data.readjust.scale\n",
    "readjust_center = np.array([0., 0., 0.])\n",
    "readjust_scale = np.array([1., 1., 1.]) # * 1.1\n",
    "# save adjusted values\n",
    "readjust = {\n",
    "    'scale': readjust_scale.tolist(),\n",
    "    'trans': readjust_center.tolist()\n",
    "}\n",
    "redjust_fname = f'{colmap_path}/readjust.json'\n",
    "with open(redjust_fname, \"w\") as outputfile:\n",
    "    json.dump(readjust, outputfile, indent=2)\n",
    "# ------------------------------------------------------------------------------------\n",
    "if trans.ndim == 1:\n",
    "    trans += readjust_center\n",
    "scale *= readjust_scale\n",
    "# Make some points to hallucinate a bounding sphere.\n",
    "# sphere_points = np.random.randn(100000, 3)\n",
    "sphere_points = np.random.rand(100000, 3) * 2 - 1\n",
    "# sphere_points = sphere_points / np.linalg.norm(sphere_points, axis=-1, keepdims=True) # Unit sphere\n",
    "# sphere_points[:, 0] = -1 # up\n",
    "for i in range(3): sphere_points[i::3, i] = sphere_points[i::3, i] / np.abs(sphere_points[i::3, i]) # Unit cube\n",
    "sphere_points = np.concatenate([sphere_points, np.zeros([1, 3])], axis=0) # center point\n",
    "# sphere_points[-1, 0] = 5\n",
    "\n",
    "sphere_points = inv_normalize_pts(sphere_points, trans, scale)\n",
    "\n",
    "# sphere_points[:, 1] = -1.1\n",
    "\n",
    "# sample up cameras\n",
    "if view_sample_camera:\n",
    "    height = poses[:, 1, 3].mean()\n",
    "    # height = -1\n",
    "    # sample_poses = cubic_camera(200, trans, scale)\n",
    "    # sample_poses = around_camera(500, trans, scale, height)\n",
    "    # sample_poses = bb_camera(500, trans, scale, height, up=False, around=True)\n",
    "    sample_poses = bb_camera(200, trans, scale, height=height, up=True, around=True, bidirect=True) # , look_mode='direction'\n",
    "    # sample_poses = up_camera(500, trans, scale)\n",
    "    # sample_poses = grid_camera(trans, scale)\n",
    "\n",
    "    # sample_poses = torch.from_numpy(poses[:, :3])\n",
    "    sample_poses = sample_poses[:, :3]\n",
    "\n",
    "    # poses = torch.cat([poses, sample_poses], dim=0)\n",
    "    poses = sample_poses # [::6]\n",
    "    # print(f\"# poses: {len(poses)}\")\n",
    "\n",
    "    # print(f\"center: {trans[:3, 3:].T}\")\n",
    "    # print(f\"scale: {scale}\")\n",
    "    # print(\"up: {}\".format(trans[1, 3] - scale[1] * 0.5))\n",
    "    # print(f\"max: {sphere_points.max(0)}\")\n",
    "    # print(f\"min: {sphere_points.min(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986aed0-1aaf-4772-937c-136db7f2eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose to visualize with Plotly...\n",
    "x, y, z = *xyzs.T,\n",
    "colors = rgbs / 255.0\n",
    "sphere_x, sphere_y, sphere_z = *sphere_points.T,\n",
    "sphere_colors = [\"#4488ff\"] * len(sphere_points)\n",
    "sphere_size = [0.5] * len(sphere_points)\n",
    "sphere_colors[-1] = \"#ff0000\" # #ff4444 center point\n",
    "# sphere_size[-1] = 5\n",
    "# traces_poses = visualize.plotly_visualize_pose(poses, vis_depth=vis_depth, xyz_length=0.02, center_size=0.01, xyz_width=0.005, mesh_opacity=0.05)\n",
    "traces_poses = plotly_visualize_pose(poses, vis_depth=vis_depth, xyz_length=0.02, center_size=0.01, xyz_width=0.005, mesh_opacity=0.05)\n",
    "trace_points = go.Scatter3d(x=x, y=y, z=z, mode=\"markers\", marker=dict(size=0.4, color=colors, opacity=0.7), hoverinfo=\"skip\")\n",
    "trace_sphere = go.Scatter3d(x=sphere_x, y=sphere_y, z=sphere_z, mode=\"markers\", marker=dict(size=sphere_size, color=sphere_colors, opacity=0.7), hoverinfo=\"skip\")\n",
    "traces_all = traces_poses + [trace_points, trace_sphere]\n",
    "layout = go.Layout(scene=dict(xaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
    "                              yaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
    "                              zaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
    "                              xaxis_title=\"X\", yaxis_title=\"Y\", zaxis_title=\"Z\", dragmode=\"orbit\",\n",
    "                              aspectratio=dict(x=1, y=1, z=1), aspectmode=\"data\"), height=800)\n",
    "fig = go.Figure(data=traces_all, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde170b-4546-4617-9162-a9fcb936347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or visualize with K3D.\n",
    "plot = k3d.plot(name=\"poses\", height=800, camera_rotate_speed=5.0, camera_zoom_speed=3.0, camera_pan_speed=1.0)\n",
    "# k3d_objects = visualize.k3d_visualize_pose(poses, vis_depth=vis_depth, xyz_length=0.02, center_size=0.01, xyz_width=0.005, mesh_opacity=0.05)\n",
    "k3d_objects = k3d_visualize_pose(poses, vis_depth=vis_depth, xyz_length=0.02, center_size=0.01, xyz_width=0.005, mesh_opacity=0.05)\n",
    "for k3d_object in k3d_objects:\n",
    "    plot += k3d_object\n",
    "plot += k3d.points(xyzs, colors=rgbs_int32, point_size=0.02, shader=\"flat\")\n",
    "plot += k3d.points(sphere_points, color=0x4488ff, point_size=0.01, shader=\"flat\")\n",
    "plot.display()\n",
    "plot.camera_fov = 30.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
